---
page_title: "openai_chat_completion Data Source - terraform-provider-openai"
subcategory: ""
description: |-
  Generate chat completions from OpenAI's GPT models during the plan phase.
---

# openai_chat_completion Data Source

Generates chat completions using OpenAI's GPT models during the Terraform plan phase. This data source is similar to the `openai_chat_completion` resource but is evaluated during `terraform plan` rather than during `terraform apply`.

## Example Usage

```terraform
data "openai_chat_completion" "plan_time_completion" {
  model = "gpt-4"

  messages = [
    {
      role    = "system"
      content = "You are a technical documentation writer specializing in cloud infrastructure."
    },
    {
      role    = "user"
      content = "Write a brief description of Amazon S3 service."
    }
  ]

  temperature = 0.5
  max_tokens  = 150
}

# Use the response in other resources
resource "local_file" "documentation" {
  filename = "s3_description.txt"
  content  = data.openai_chat_completion.plan_time_completion.response_content[0]
}
```

## Argument Reference

- `model` - (Required) ID of the model to use for completion (e.g., 'gpt-4', 'gpt-3.5-turbo').
- `messages` - (Required) A list of messages comprising the conversation so far. Each message object contains:
  - `role` - (Required) The role of the message author. Can be 'system', 'user', or 'assistant'.
  - `content` - (Required) The content of the message.
- `temperature` - (Optional) Sampling temperature between 0 and 2. Higher values like 0.8 make output more random, while lower values like 0.2 make it more focused and deterministic.
- `top_p` - (Optional) An alternative to sampling with temperature, called nucleus sampling. Set this between 0 and 1.
- `n` - (Optional) How many completion choices to generate. Default is 1.
- `max_tokens` - (Optional) Maximum number of tokens to generate.

## Attribute Reference

In addition to all arguments above, the following attributes are exported:

- `id` - Unique identifier for this data source.
- `response_content` - The completion(s) generated by the model. For n=1, this will be a list with a single element.
- `response_role` - The role of the returned message. Typically 'assistant'.
